{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef149ad-35f5-4fae-abc3-ea954fae94bf",
   "metadata": {},
   "source": [
    "See this link for a model: https://huggingface.co/nlpaueb/legal-bert-base-uncased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f4aad-6b51-44ce-af20-0daf52d04288",
   "metadata": {},
   "source": [
    "<h1> Legal explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41282f80-4b97-48ff-8a34-e892372f05db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter-resource-usage 0.6.3 has requirement jupyter-server~=1.0, but you have jupyter-server 2.4.0.\n",
      "jupyterlab-server 2.27.2 has requirement requests>=2.31, but you have requests 2.28.2.\n",
      "langchain 0.3.1 has requirement pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.18.\n",
      "langchain-core 0.3.8 has requirement pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.18.\n",
      "xgboost 1.6.2 is not supported on this platform\n"
     ]
    }
   ],
   "source": [
    "!pip check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ce92678-fc0f-43ec-8b2e-ed861d4640e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'field_validator' from 'pydantic' (/home/dancinoman/.pyenv/versions/lewagon/lib/python3.10/site-packages/pydantic/__init__.cpython-310-x86_64-linux-gnu.so)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatAnthropic, ChatOpenAI\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate, LLMChain, HuggingFaceHub \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     ChatPromptTemplate,\n\u001b[1;32m      5\u001b[0m     SystemMessagePromptTemplate,\n\u001b[1;32m      6\u001b[0m     AIMessagePromptTemplate,\n\u001b[1;32m      7\u001b[0m     HumanMessagePromptTemplate,\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/langchain/chat_models/__init__.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LangChainDeprecationWarning\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minteractive_env\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_interactive_env\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init_chat_model\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chat_models\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/langchain/chat_models/base.py:23\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     Any,\n\u001b[1;32m      7\u001b[0m     AsyncIterator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     overload,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m beta\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     BaseChatModel,\n\u001b[1;32m     25\u001b[0m     LanguageModelInput,\n\u001b[1;32m     26\u001b[0m     SimpleChatModel,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     agenerate_from_stream,\n\u001b[1;32m     30\u001b[0m     generate_from_stream,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnyMessage, BaseMessage\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/langchain_core/language_models/__init__.py:42\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"**Language Model** is a type of model that can generate text or complete\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mtext prompts.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     43\u001b[0m     BaseLanguageModel,\n\u001b[1;32m     44\u001b[0m     LangSmithParams,\n\u001b[1;32m     45\u001b[0m     LanguageModelInput,\n\u001b[1;32m     46\u001b[0m     LanguageModelLike,\n\u001b[1;32m     47\u001b[0m     LanguageModelOutput,\n\u001b[1;32m     48\u001b[0m     get_tokenizer,\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseChatModel, SimpleChatModel\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FakeListLLM, FakeStreamingListLLM\n",
      "File \u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.10/site-packages/langchain_core/language_models/base.py:16\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     TYPE_CHECKING,\n\u001b[1;32m      8\u001b[0m     Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     Union,\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, ConfigDict, Field, field_validator\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TypeAlias, TypedDict, override\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'field_validator' from 'pydantic' (/home/dancinoman/.pyenv/versions/lewagon/lib/python3.10/site-packages/pydantic/__init__.cpython-310-x86_64-linux-gnu.so)"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatAnthropic, ChatOpenAI\n",
    "from langchain import PromptTemplate, LLMChain, HuggingFaceHub \n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "import PyPDF2\n",
    "import torch\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class LegalExpert:\n",
    "    def __init__(self):\n",
    "        self.system_prompt = self.get_system_prompt()\n",
    "\n",
    "        self.user_prompt = HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "\n",
    "        full_prompt_template = ChatPromptTemplate.from_messages(\n",
    "            [self.system_prompt, self.user_prompt]\n",
    "        )\n",
    "\n",
    "        # falcon model\n",
    "        model_name = \"tiiuae/falcon-7b-instruct\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.falcon_llm = pipeline(\"text-generation\", \n",
    "                                   model=model_name, \n",
    "                                   tokenizer=tokenizer,\n",
    "                                   torch_dtype=torch.float16,\n",
    "                                   trust_remote_code=True,\n",
    "                                   device_map=\"auto\")\n",
    "    \n",
    "\n",
    "        # create llm pipeline for model\n",
    "        model_name = \"google/flan-t5-xl\"\n",
    "        \n",
    "        self.huggingface_llm = pipeline(\"text-generation\", model=model_name, tokenizer=AutoTokenizer.from_pretrained(model_name))\n",
    "\n",
    "        self.openai_gpt4_llm = ChatOpenAI(temperature=0, max_tokens=256)\n",
    "        # self.chat = ChatAnthropic()\n",
    "\n",
    "        self.chain = LLMChain(llm=self.huggingface_llm, prompt=full_prompt_template)\n",
    "\n",
    "    def get_system_prompt(self):\n",
    "        system_prompt = \"\"\"\n",
    "        You are a Canadian Legal Expert. \n",
    "        Under no circumstances do you give legal advice.\n",
    "        \n",
    "        You are adept at explaining the law in laymans terms, and you are able to provide context to legal questions.\n",
    "        While you can add context outside of the provided context, please do not add any information that is not directly relevant to the question, or the provided context.\n",
    "        You speak {language}.\n",
    "        ### CONTEXT\n",
    "        {context}\n",
    "        ### END OF CONTEXT\n",
    "        \"\"\"\n",
    "\n",
    "        return SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "\n",
    "    def run_chain(self, language, context, question):\n",
    "        return self.chain.run(\n",
    "            language=language, context=context, question=question\n",
    "        )\n",
    "\n",
    "\n",
    "def retrieve_pdf_text(pdf_file):\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "# create a streamlit app\n",
    "st.title(\"Document Explainer (that does not give advice)\")\n",
    "\n",
    "if \"LegalExpert\" not in st.session_state:\n",
    "    st.session_state.LegalExpert = LegalExpert()\n",
    "\n",
    "# create a upload file widget for a pdf\n",
    "pdf_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"])\n",
    "\n",
    "st.session_state.context = None\n",
    "# if a pdf file is uploaded\n",
    "if pdf_file:\n",
    "    # retrieve the text from the pdf\n",
    "    if \"context\" not in st.session_state:\n",
    "        st.session_state.context = retrieve_pdf_text(pdf_file)\n",
    "\n",
    "# create a button that clears the context\n",
    "if st.button(\"Clear context\"):\n",
    "    st.session_state.__delitem__(\"context\")\n",
    "    st.session_state.__delitem__(\"legal_response\")\n",
    "\n",
    "# if there's context, proceed\n",
    "if \"context\" in st.session_state:\n",
    "    # create a dropdown widget for the language\n",
    "    language = st.selectbox(\"Language\", [\"English\", \"Fran√ßais\"])\n",
    "    # create a text input widget for a question\n",
    "    question = st.text_input(\"Ask a question\")\n",
    "\n",
    "    # create a button to run the model\n",
    "    if st.button(\"Run\"):\n",
    "        # run the model\n",
    "        legal_response = st.session_state.LegalExpert.run_chain(\n",
    "            language=language, context=st.session_state.context, question=question\n",
    "        )\n",
    "        print(f\"legal_response: {legal_response}\")\n",
    "        if \"legal_response\" not in st.session_state:\n",
    "            st.session_state.legal_response = legal_response\n",
    "\n",
    "        else:\n",
    "            st.session_state.legal_response = legal_response\n",
    "\n",
    "# display the response\n",
    "if \"legal_response\" in st.session_state:\n",
    "    st.write(st.session_state.legal_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
